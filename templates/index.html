{% extends "base.html" %}

{% block title %}Home - Hue Shift{% endblock %}

{% block content %}
<!-- Hero Section -->
<div class="jumbotron p-5 bg-light rounded">
    <div class="row">
        <div class="col-md-7">
            <h1 class="display-4">HueShift: Breathing Life into Every Frame</h1>
            <div class="mt-4">
                <a href="{{ url_for('gallery') }}" class="btn btn-outline-primary btn-lg ms-2">View Gallery</a>
            </div>
        </div>
        <div class="col-md-5">
            <img src="{{ url_for('static', filename='images/hero-image.jpg') }}" alt="HueShift Demo" class="img-fluid rounded shadow">
        </div>
    </div>
</div>

<!-- Project Overview Section -->
<section class="my-5">
    <div class="container">
        <h2 class="text-center mb-4">Project Overview</h2>
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <p class="lead text-center">
                    HueShift is a video colorization project that transforms grayscale videos into vibrant color
                    using two different deep learning approaches: Diffusion Models and Generative Adversarial Networks (GANs).
                    Our goal was to develop and compare these two methods, with a special focus on ensuring temporal consistency
                    and realistic coloration across frames.
                </p>
            </div>
        </div>
    </div>
</section>
<!-- Why Video Colorization Section -->
<!--
<section class="my-5 bg-light py-5">
    <div class="container">
        <h2 class="text-center mb-4">Why Video Colorization?</h2>
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <p>Colorization enhances visual quality and usability of grayscale media, opening new possibilities for:</p>
                <div class="row mt-4">
                    <div class="col-md-6">
                        <div class="card mb-3 h-100">
                            <div class="card-body">
                                <h5 class="card-title"><i class="bi bi-film text-primary me-2"></i>Historical Film Restoration</h5>
                                <p class="card-text">Revive historical footage with realistic color, making history more engaging.</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="card mb-3 h-100">
                            <div class="card-body">
                                <h5 class="card-title"><i class="bi bi-palette text-primary me-2"></i>Artistic Enhancement</h5>
                                <p class="card-text">Transform creative works, giving new life to old artistic visuals.</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="card mb-3 h-100">
                            <div class="card-body">
                                <h5 class="card-title"><i class="bi bi-camera-reels text-primary me-2"></i>Media Production</h5>
                                <p class="card-text">Streamline post-production workflows with automated colorization.</p>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="card mb-3 h-100">
                            <div class="card-body">
                                <h5 class="card-title"><i class="bi bi-book text-primary me-2"></i>Educational Content</h5>
                                <p class="card-text">Enhance learning materials with vibrant color, improving engagement.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
-->

<!-- Our Dual Approach Section -->
<section class="my-5">
    <div class="container">
        <h2 class="text-center mb-5">Our Dual Approach</h2>
        
        <!-- Diffusion Model -->
        <div class="row align-items-center mb-5">
            <div class="col-lg-6">
                <h3>1. Diffusion-Based Approach</h3>
                <p>Our diffusion model works by iteratively adding and removing noise:</p>
                <ul>
                    <li><strong>LAB Color Space Processing</strong> - Separates luminance ("L" channel) from color ("A" and "B" channels), allowing us to denoise only color components</li>
                    <li><strong>U-Net Architecture</strong> - A 3-channel LAB input with noised AB channels passes through encoder, bottleneck, and decoder with skip connections</li>
                    <li><strong>Noise Scheduling</strong> - Carefully calibrated variance schedule controls the noise addition/removal process</li>
                    <li><strong>Forward Process</strong> - Gaussian noise is added to color channels in increasing amounts over T timesteps</li>
                    <li><strong>Reverse Process</strong> - The model learns to predict and remove noise iteratively, conditioned on grayscale input</li>
                    <li><strong>Resolution Enhancement</strong> - Bicubic interpolation upscales low-resolution outputs while preserving original grayscale details</li>
                    <li><strong>Neural Deflickering</strong> - Flawed atlas approach identifies and corrects temporal inconsistencies between frames</li>
                </ul>
                <a href="{{ url_for('gallery_new') }}" class="btn btn-outline-primary mt-3">See Diffusion Results</a>
            </div>
            <div class="col-lg-6">
                <img src="{{ url_for('static', filename='images/diffusion_process.jpg') }}" alt="Diffusion Model Process" class="img-fluid rounded shadow">
            </div>
        </div>
        
        <!-- GAN Model -->
        <div class="row align-items-center flex-row-reverse">
            <div class="col-lg-6">
                <h3>2. GAN-Based Approach</h3>
                <p>Our GAN implementation uses saliency maps to guide colorization:</p>
                <ul>
                    <li><strong>SCGAN-Based Generator</strong> - Modified with channel reduction at deeper layers for improved training stability</li>
                    <li><strong>Saliency Detection</strong> - Pyramid Feature Attention Network identifies visually important regions</li>
                    <li><strong>70Ã—70 PatchGAN Discriminators</strong>:
                        <ul>
                            <li>Standard discriminator - Enforces global color realism</li>
                            <li>Attention discriminator - Focuses on salient regions for detail refinement</li>
                        </ul>
                    </li>
                    <li><strong>Loss Functions</strong> - Balanced combination of adversarial, L1, and perceptual losses</li>
                    <li><strong>Optical Flow</strong> - FastFlowNet tracks motion between frames to maintain color consistency</li>
                    <li><strong>Adaptive Color Propagation</strong> - Warps colors from keyframes to subsequent frames based on motion vectors</li>
                </ul>
                <a href="{{ url_for('gallery') }}?tab=gan" class="btn btn-outline-primary mt-3">See GAN Results</a>
            </div>
            <div class="col-lg-6">
                <img src="{{ url_for('static', filename='images/gan_process.jpg') }}" alt="GAN Model Process" class="img-fluid rounded shadow">
            </div>
        </div>
    </div>
</section>

<!-- Technical Challenges -->
<section class="my-5 bg-light py-5">
    <div class="container">
        <h2 class="text-center mb-4">Technical Challenges & Solutions</h2>
        <div class="row">
            <div class="col-md-6">
                <div class="card border-0 shadow-sm h-100">
                    <div class="card-body">
                        <h4 class="card-title"><i class="bi bi-bezier2 text-primary me-2"></i>Temporal Consistency</h4>
                        <p class="card-text">To prevent color flickering between frames, we:</p>
                        <ul>
                            <li>Applied neural filtering for stable color transitions</li>
                            <li>Implemented frame-to-frame motion analysis</li>
                            <li>Used atlas-based deflickering techniques</li>
                            <li>Two-stage processing: low-res colorization with high-res upscaling</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Sample Results -->
<section class="my-5">
    <div class="container">
        <h2 class="text-center mb-4">Sample Results</h2>
        <div class="row">
            <div class="col-md-6">
                <div class="card mb-4">
                    <div class="card-header bg-primary text-white">
                        <h5 class="mb-0">Diffusion Model</h5>
                    </div>
                    <div class="card-body p-0">
                        <video class="w-100" autoplay loop muted>
                            <source src="{{ url_for('static', filename='gallery/diffusion/v_ApplyLipstick_g05_c04/concatenated/output.mp4') }}" type="video/mp4">
                        </video>
                    </div>
                    <div class="card-footer">
                        <p class="mb-0">Sample 1 - Apply Lipstick (Combined View)</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="card mb-4">
                    <div class="card-header bg-primary text-white">
                        <h5 class="mb-0">GAN Model</h5>
                    </div>
                    <div class="card-body p-0">
                        <video class="w-100" autoplay loop muted>
                            <source src="{{ url_for('static', filename='gallery/gan/simple/v_HorseRiding_g03_c04.mp4') }}" type="video/mp4">
                        </video>
                    </div>
                    <div class="card-footer">
                        <p class="mb-0">Horse Riding (Simple Scene)</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- References Section -->
<section class="my-5">
    <div class="container">
        <h2 class="text-center mb-4">References & Resources</h2>
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <div class="list-group">
                    <a href="https://arxiv.org/abs/2006.11239" target="_blank" class="list-group-item list-group-item-action">
                        <div class="d-flex w-100 justify-content-between">
                            <h5 class="mb-1">Denoising Diffusion Probabilistic Models</h5>
                        </div>
                        <p class="mb-1">The foundation for our diffusion-based approach</p>
                    </a>
                    <a href="https://arxiv.org/abs/2303.08120" target="_blank" class="list-group-item list-group-item-action">
                        <div class="d-flex w-100 justify-content-between">
                            <h5 class="mb-1">Blind Video Deflickering by Neural Filtering with a Flawed Atlas</h5>
                        </div>
                        <p class="mb-1">Used for ensuring temporal consistency in our diffusion approach</p>
                    </a>
                    <a href="https://arxiv.org/abs/2011.05108" target="_blank" class="list-group-item list-group-item-action">
                        <div class="d-flex w-100 justify-content-between">
                            <h5 class="mb-1">SCGAN: Saliency Map-guided Colorization with Generative Adversarial Network</h5>
                        </div>
                        <p class="mb-1">The basis for our GAN-based approach</p>
                    </a>
                </div>
                <div class="mt-4 text-center">
                    <a href="https://github.com/Kazedaa/Hueshift-Video-Coloring" target="_blank" class="btn btn-outline-primary me-2">
                        <i class="bi bi-github me-1"></i>Diffusion Approach
                    </a>
                    <a href="https://github.com/SreeDakshinya/HueShift-Video-Coloring/tree/main" target="_blank" class="btn btn-outline-primary">
                        <i class="bi bi-github me-1"></i>GAN Approach
                    </a>
                </div>
            </div>
        </div>
    </div>
</section>

{% endblock %} 